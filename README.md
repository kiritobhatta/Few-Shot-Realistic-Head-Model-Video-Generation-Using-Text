# Few-Shot Realistic Head Model Video Generation Using Text  [![DES2](https://img.shields.io/static/v1?label=ML/DL&message=FYP-DES2&color=<COLOR>&labelColor=green)](https://github.com/kiritobhatta/Few-Shot-Realistic-Head-Model-Video-Generation-Using-Text.git)
> This repository contains our codebase for our preliminary work done for our Final-Year Project.

For our Final-Year Project, we present a system capable of automatically generating videos of talking head models using short source video without constant supervision on the process. Our work primarily involves the task of automatically synthesizing a video of a given input text by using the patterns of appearance and speech extracted from a short source video. The system will be able to generate results using a few shots of data by initializing the parameters in the meta-learning model, which is trained on large datasets, in a person-specific way. This system can potentially be applied to applications such as personalized virtual A.I. assistants, stand-up shows, and podcasts. Moreover, our work is relevant to the general, hearing-impaired, and old population who rely on visual cues from the speaker's face and features such as lips and eyes to comprehend the information provided by the speaker. We believe that our system fills the niche of an alternative approach for the efficient and simple synthesis of realistic talking videos.

## Implementation
All of our work is based on open sourced github projects. We have implemented all of our preliminary work on Google Colab so that it is easy to replicate the same results.

## Results
The results produced by the code provided in this repository can be found in this [google drive](https://drive.google.com/drive/folders/1sCKzGWNhHi_8bIEsLsR5nKnr62XD0qkI?usp=sharing).

## Contribution
This repository is for the Final year project for the *Hong Kong University of Science and Technology(HKUST)* on the topic of ***Few-Shot Realistic Head Model Video Generation Using Text*** by *BHATT, Umakant Datt, SHRESTHA Aayush and SUNG Ka Hong* under the supervision of *Prof. Desmond Yau-chat Tsoi*.

